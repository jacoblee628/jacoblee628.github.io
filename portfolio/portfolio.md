---
title: Portfolio
layout: archive
permalink: /portfolio/
# collection: portfolio
# entries_layout: grid
author_profile: true
---
# Portfolio

### 11-785 Introduction to Deep Learning (CMU)
Did a lot of stuff for the [11-785 Introduction to Deep Learning](http://deeplearning.cs.cmu.edu/F20/index.html) course at CMU.

-----

#### Homeworks

<a href="http://deeplearning.cs.cmu.edu/F20/document/homework/Homework_1_1.pdf"><img src="../assets/images/hw1p1.png" width="500"/></a>

**Description:**

Wrote four homework assignments for the course:
* [hw1](http://deeplearning.cs.cmu.edu/F20/document/homework/Homework_1_1.pdf): Recreating [PyTorch](https://pytorch.org/) and automatic differentiation
* [hw1bonus](http://deeplearning.cs.cmu.edu/F20/document/homework/Homework_1_Bonus.pdf): Adam, Dropout, and BatchNorm
* [hw2](http://deeplearning.cs.cmu.edu/F20/document/homework/Homework_2_1.pdf): Convolutional Neural Networks (CNNs)
* [hw2bonus](http://deeplearning.cs.cmu.edu/F20/document/homework/Homework_2_Bonus.pdf): 2d Convolutional Networks

-----

#### Recitations - Matrix Calc and Homework Bootcamp
<iframe src="https://youtube.com/embed/PB0yQlFU2Ds" frameborder="0" allowfullscreen></iframe>

<iframe src="https://youtube.com/embed/MARCktJrk0s" frameborder="0" allowfullscreen></iframe>

-----
#### Misc

Answered over 3400 student questions on Piazza

<img src="../assets/images/my_stats.png" width="900"/>

Our average response time (24/7) was 5 minutes per question

<img src="../assets/images/piazza_stats.png" width="300"/>

<!-- ## Speech-to-Text with Listen Attend Spell
<img src="/assets/images/asr.png" title="img source:https://analyticsindiamag.com/all-the-tech-you-need-to-know-that-powers-speech-to-text-on-your-device/" alt="Automatic Speech Recognition" width="400">

Trained a network that converts input audio directly to text. Implemented [Listen Attend Spell (Chan et al, 2015)](https://arxiv.org/abs/1508.01211) using only PyTorch, trained on AWS. Placed #17 of 278 students in the course.

-----

## Word Prediction with the AWD-LSTM
<img src="/assets/images/text_generator.jpeg" title="img source:https://medium.com/towards-artificial-intelligence/sentence-prediction-using-word-level-lstm-text-generator-language-modeling-using-rnn-a80c4cda5b40" alt="Word Prediction" width="400">

Trained a network that generates text. Implemented the heavily regularized [AWD-LSTM (Merity et al, 2018)](https://arxiv.org/abs/1708.02182), manually implementing regularization methods such as Locked Dropout, Embedding Dropout, and Weight Tying. 

-----

## Machine Learning from Scratch
<img src="/assets/images/from_scratch.jpg" title="img source:https://www.oxy.edu/academics/areas-study/computer-science" alt="Deep Learning from Scratch" width="400">

Implemented a variety of ML/DL algorithms from scratch. Optimizers, network architectures, search algorithms, and more. -->